{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stack_segmentation.stack import Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stack_segmentation.aug_pipelines import medium_aug\n",
    "from stack_segmentation.io import make_dataloader, collate_fn_basic\n",
    "from stack_segmentation.training import handle_stacks_data, make_model, train_loop\n",
    "from stack_segmentation.unet import UNet\n",
    "from stack_segmentation.pipeline_config import dataloaders_conf, model_conf, train_conf, loss_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_config import data_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conf['device'] = 'cpu'\n",
    "model_conf['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conf_name': 'basic_lr1e-3_epoch300',\n",
       " 'stacks': [{'path': '../../data/carb96558',\n",
       "   'slice_train': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, 230, None)),\n",
       "   'slice_val': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(250, 470, None))},\n",
       "  {'path': '../../data/SoilB-2',\n",
       "   'slice_train': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, 230, None)),\n",
       "   'slice_val': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(240, 460, None))},\n",
       "  {'path': '../../data/Urna_22',\n",
       "   'slice_train': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, 220, None)),\n",
       "   'slice_val': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(245, 455, None))},\n",
       "  {'path': '../../data/carb96558',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(490, None, None))},\n",
       "  {'path': '../../data/carb71',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/carbRNF',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/SPE_carb10_58_box3',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/SoilAh-1',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/SoilB-2',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/TeTree_subset1',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/TiTree_subset2',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/Urna_22',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/Urna_30',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))},\n",
       "  {'path': '../../data/Urna_34',\n",
       "   'slice_test': (slice(None, None, None),\n",
       "    slice(None, None, None),\n",
       "    slice(None, None, None))}],\n",
       " 'patches': {'train': (128, 128, 1),\n",
       "  'val': (128, 128, 1),\n",
       "  'test': (128, 128, 1)}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_conf['conf_name'] = 'basic_lr1e-3_epoch300'\n",
    "data_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'batch_size': 32,\n",
       "  'num_workers': 8,\n",
       "  'shuffle': True,\n",
       "  'augmentation_pipeline': None},\n",
       " 'val': {'batch_size': 32,\n",
       "  'num_workers': 8,\n",
       "  'shuffle': False,\n",
       "  'augmentation_pipeline': None},\n",
       " 'test': {'batch_size': 32,\n",
       "  'num_workers': 8,\n",
       "  'shuffle': True,\n",
       "  'augmentation_pipeline': None}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders_conf['train']['augmentation_pipeline'] = None\n",
    "dataloaders_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_epochs': 300, 'device': 'cpu'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_conf['num_epochs'] = 300\n",
    "train_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'opt_type': 'SGD',\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 0.0001,\n",
       " 'amsgrad': False,\n",
       " 'nesterov': True,\n",
       " 'momentum': 0.9,\n",
       " 'centered': False,\n",
       " 'min_lr': 1e-06,\n",
       " 'factor': 0.5,\n",
       " 'patience': 5,\n",
       " 'weight': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conf['opt_type'] = 'SGD'\n",
    "model_conf['lr'] = 1e-3\n",
    "model_conf['weight'] = None\n",
    "model_conf['nesterov'] = True\n",
    "model_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (128, 128, 1), 'val': (128, 128, 1), 'test': (128, 128, 1)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_conf['patches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "720it [00:01, 694.81it/s]\n",
      "100%|██████████| 720/720 [00:07<00:00, 93.11it/s] \n",
      "8280it [00:00, 238881.54it/s]\n",
      "7920it [00:00, 249424.75it/s]\n",
      "700it [00:00, 863.35it/s]\n",
      "100%|██████████| 700/700 [00:07<00:00, 98.70it/s] \n",
      "8280it [00:00, 250881.96it/s]\n",
      "7920it [00:00, 81817.91it/s]\n",
      "710it [00:00, 829.65it/s]\n",
      "100%|██████████| 710/710 [00:07<00:00, 94.78it/s] \n",
      "7920it [00:00, 246969.56it/s]\n",
      "7560it [00:00, 236762.85it/s]\n",
      "720it [00:00, 799.16it/s]\n",
      "100%|██████████| 720/720 [00:07<00:00, 90.82it/s] \n",
      "8280it [00:00, 256378.96it/s]\n",
      "720it [00:00, 820.24it/s]\n",
      "100%|██████████| 720/720 [00:07<00:00, 93.26it/s] \n",
      "25920it [00:00, 118542.46it/s]\n",
      "700it [00:00, 850.66it/s]\n",
      "100%|██████████| 700/700 [00:07<00:00, 99.06it/s] \n",
      "25200it [00:00, 133520.54it/s]\n",
      "509it [00:00, 1163.95it/s]\n",
      "100%|██████████| 509/509 [00:02<00:00, 195.62it/s]\n",
      "8144it [00:00, 189609.89it/s]\n",
      "700it [00:00, 833.01it/s]\n",
      "100%|██████████| 700/700 [00:07<00:00, 98.91it/s] \n",
      "25200it [00:00, 231519.36it/s]\n",
      "700it [00:00, 814.58it/s]\n",
      "100%|██████████| 700/700 [00:07<00:00, 97.29it/s] \n",
      "25200it [00:00, 122938.74it/s]\n",
      "710it [00:01, 406.08it/s]\n",
      "100%|██████████| 710/710 [00:07<00:00, 94.80it/s] \n",
      "25560it [00:00, 227203.95it/s]\n",
      "710it [00:01, 404.88it/s]\n",
      "100%|██████████| 710/710 [00:07<00:00, 94.77it/s] \n",
      "25560it [00:00, 116954.83it/s]\n",
      "710it [00:00, 816.51it/s]\n",
      "100%|██████████| 710/710 [00:07<00:00, 95.32it/s] \n",
      "25560it [00:00, 231464.83it/s]\n",
      "710it [00:00, 847.55it/s]\n",
      "100%|██████████| 710/710 [00:07<00:00, 98.15it/s] \n",
      "25560it [00:00, 231336.97it/s]\n",
      "700it [00:00, 857.82it/s]\n",
      "100%|██████████| 700/700 [00:06<00:00, 101.00it/s]\n",
      "25200it [00:00, 112856.05it/s]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_val, data_test = handle_stacks_data(**data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24480, 23400, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train), len(data_val), len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = make_dataloader(\n",
    "    samples=data_train, \n",
    "    collate_fn=collate_fn_basic,\n",
    "    **dataloaders_conf['train']\n",
    ")\n",
    "\n",
    "dataloader_val = make_dataloader(\n",
    "    samples=data_val, \n",
    "    collate_fn=collate_fn_basic,\n",
    "    **dataloaders_conf['val']\n",
    ")\n",
    "\n",
    "dataloaders_test = {\n",
    "    name: make_dataloader(\n",
    "        samples=data, \n",
    "        collate_fn=collate_fn_basic,\n",
    "        **dataloaders_conf['test']\n",
    "    ) for name, data in data_test.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stack_segmentation.metrics import accuracy, precision, recall, f1, pr_auc, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': accuracy, \n",
    "    'precision': precision, \n",
    "    'recall': recall, \n",
    "    'f1': f1,\n",
    "    'pr_auc': pr_auc, \n",
    "    'iou': iou,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion, optimizer, scheduler = make_model(loss_config=loss_config, **model_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_loop(\n",
    "    model=model,\n",
    "    dataloader_train=dataloader_train, \n",
    "    dataloader_val=dataloader_val,\n",
    "    dataloaders_test=dataloaders_test,\n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler,\n",
    "    metrics=metrics,\n",
    "    exp_name=data_conf['conf_name'],\n",
    "    **train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './{}_exp_results.pkl'.format(data_conf['conf_name'])\n",
    "with open(p, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = './{}_exp_results.pkl'.format(data_conf['conf_name'])\n",
    "# with open(p, 'rb') as f:\n",
    "#     results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('./{}.pt'.format(data_conf['conf_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = list(chain(*[item for item in results['train_losses']]))\n",
    "val_losses = list(chain(*[item for item in results['val_losses']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=5) :\n",
    "    ret = np.cumsum([a[0]] * (n - 1) + a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Moving-averaged batch losses')\n",
    "plt.plot(np.arange(len(train_losses)), moving_average(train_losses), label='train')\n",
    "plt.plot(np.arange(len(val_losses)), moving_average(val_losses), label='validation')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "\n",
    "# plt.ylim([1e-2, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_train_loss = [np.mean(item) for item in results['train_losses']]\n",
    "mean_val_loss = [np.mean(item) for item in results['val_losses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Epoch losses')\n",
    "plt.plot(np.arange(len(mean_train_loss)) + 1, mean_train_loss, label='train')\n",
    "plt.plot(np.arange(len(mean_val_loss)) + 1, mean_val_loss, label='val')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.xlim([1, len(mean_train_loss) + 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_utils import make_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_df(results, model_name='basic')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean   IOU: {:.5}'.format(df['iou'].mean()))\n",
    "print('Std    IOU: {:.5}'.format(df['iou'].std()))\n",
    "print('Min    IOU: {:.5}'.format(df['iou'].min()))\n",
    "print('Median IOU: {:.5}'.format(df['iou'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataloader_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 1, 128, 128), (32, 128, 128))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8451, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "dice = DiceLoss(mode='multiclass', log_loss=True, smooth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolbelt.losses import DiceLoss, JointLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7135, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1725, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 128, 128]), torch.Size([32, 2, 128, 128]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(), pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = JointLoss(ce, dice, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8860, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'weight': [1, 10],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WeightedLoss(\n",
       "   (loss): CrossEntropyLoss()\n",
       " ), WeightedLoss(\n",
       "   (loss): DiceLoss()\n",
       " ))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9430, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pred, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_geo",
   "language": "python",
   "name": "py37_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
